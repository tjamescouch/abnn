name: "ABNN"

neurons:  65536
synapses: 524288
tau_LTP:  20_000       # ns
tau_LTD:  40_000
alpha_LTP: 0.01
alpha_LTD: 0.005
w_min: 0.001
w_max: 1.0
steps: 1_000_000
rng_seed: 42


#FIXME - this is a temporary measure

layers:
  - type: Input
    name: "input"
    output_shape: [1, 2560]
    
  - type: Dense
    name: "dense_ffn_expand"
    input_size: 2560
    output_size: 5120
    activation: relu
    initializer: he

  - type: Dense
    name: "dense_ffn_reduce"
    input_size: 5120
    output_size: 2560
    activation: linear
    initializer: xavier

training:
  optimizer:
    type: adam
    accumulation_interval: 2
    learning_rate: 0.0001
    parameters:
      beta1: 0.9
      beta2: 0.999
      epsilon: 1e-8

  epochs: 1
  batch_size: 2

dataset:
  type: "function"

metadata:
  author: "James Couch"
  description: "Feed Forward NN"

